{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Anomaly Detection in Mackey-Glass Time Series with TCN-AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/MarkusThill/bioma-tcn-ae/blob/main/src/main.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/MarkusThill/bioma-tcn-ae/blob/main/src/main.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More details to come...\n",
    "\n",
    "The following points should be considered:\n",
    "- When using Google CoLab, remember to activate GPU accelaration: \n",
    "  - Navigate to Editâ†’Notebook Settings\n",
    "  - select GPU from the Hardware Accelerator drop-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on Google CoLab!\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# First Check, if we are running in Google CoLab\n",
    "#\n",
    "IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "if IN_COLAB:\n",
    "    print('Running on Google CoLab!')\n",
    "else:\n",
    "    print('Not running on Google CoLab!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Initially, install necessary packages and download the repository (required to access the data)\n",
    "#\n",
    "import os\n",
    "if IN_COLAB:\n",
    "    !pip3 install keras-tcn\n",
    "    if not os.path.exists('/content/bioma-tcn-ae/'):\n",
    "        print(\"Repo not cloned yet. Do it now!\")\n",
    "        !git clone https://github.com/MarkusThill/bioma-tcn-ae /content/bioma-tcn-ae/\n",
    "    else:\n",
    "        print(\"Repository already cloned!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# In Google CoLab: Change the working directory to bioma-tcn-ae/src\n",
    "#\n",
    "if IN_COLAB and os.getcwd() != \"/content/bioma-tcn-ae/src\":\n",
    "  # Print the current working directory\n",
    "  print(\"Old working directory: {0}\".format(os.getcwd()))\n",
    "\n",
    "  # Change the current working directory\n",
    "  os.chdir('/content/bioma-tcn-ae/src')\n",
    "\n",
    "  # Print the current working directory\n",
    "  print(\"New working directory: {0}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# If this cell throws an error, make sure that you activated GPU acceleration, as described above!\n",
    "#\n",
    "if IN_COLAB:\n",
    "    %tensorflow_version 2.x\n",
    "    import tensorflow as tf\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "    if device_name != '/device:GPU:0':\n",
    "        raise SystemError('GPU device not found')\n",
    "    print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import time\n",
    "from utilities import select_gpus, plot_results # utilities.py: Contains a few miscellaneous functions \n",
    "from tcnae import TCNAE # tcnae.py: Specification of the TCN-AE model\n",
    "import data # data.py: Allows to generate anomalous Mackey-Glass (MG) time series \n",
    "\n",
    "# If you have several GPUs, select one or more here (in a list)\n",
    "#select_gpus(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape: (19791, 1050, 1)\n"
     ]
    }
   ],
   "source": [
    "train_ts_id = 1 # [1-10]. Train the model on Mackey-Glass time series 1\n",
    "data_gen = data.Data()\n",
    "train_data = data_gen.build_data(train_ts_id, verbose = 0) # Returns a dictionary\n",
    "train_X = train_data[\"train_X\"] # We only need train_X (input = output) for the training process\n",
    "print(\"train_X.shape:\", train_X.shape) # A lot of training sequences of length 1050 and dimension 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Starting the Training...\n",
      "Epoch 1/40\n",
      "618/618 - 16s - loss: 0.0253 - logcosh: 0.0253 - val_loss: 0.0012 - val_logcosh: 0.0012\n",
      "Epoch 2/40\n",
      "618/618 - 15s - loss: 0.0011 - logcosh: 0.0011 - val_loss: 6.6988e-04 - val_logcosh: 6.6988e-04\n",
      "Epoch 3/40\n",
      "618/618 - 15s - loss: 7.2102e-04 - logcosh: 7.2102e-04 - val_loss: 5.2625e-04 - val_logcosh: 5.2625e-04\n",
      "Epoch 4/40\n",
      "618/618 - 15s - loss: 5.8016e-04 - logcosh: 5.8015e-04 - val_loss: 4.0497e-04 - val_logcosh: 4.0497e-04\n",
      "Epoch 5/40\n",
      "618/618 - 15s - loss: 5.0331e-04 - logcosh: 5.0331e-04 - val_loss: 4.4924e-04 - val_logcosh: 4.4924e-04\n",
      "Epoch 6/40\n",
      "618/618 - 15s - loss: 4.4031e-04 - logcosh: 4.4031e-04 - val_loss: 3.5117e-04 - val_logcosh: 3.5117e-04\n",
      "Epoch 7/40\n",
      "618/618 - 15s - loss: 4.1264e-04 - logcosh: 4.1264e-04 - val_loss: 3.1991e-04 - val_logcosh: 3.1991e-04\n",
      "Epoch 8/40\n",
      "618/618 - 15s - loss: 3.8277e-04 - logcosh: 3.8277e-04 - val_loss: 3.1657e-04 - val_logcosh: 3.1657e-04\n",
      "Epoch 9/40\n",
      "618/618 - 15s - loss: 3.6420e-04 - logcosh: 3.6420e-04 - val_loss: 3.2701e-04 - val_logcosh: 3.2701e-04\n",
      "Epoch 10/40\n",
      "618/618 - 15s - loss: 3.4364e-04 - logcosh: 3.4364e-04 - val_loss: 3.1208e-04 - val_logcosh: 3.1208e-04\n",
      "Epoch 11/40\n",
      "618/618 - 15s - loss: 3.3665e-04 - logcosh: 3.3665e-04 - val_loss: 3.1559e-04 - val_logcosh: 3.1559e-04\n",
      "Epoch 12/40\n",
      "618/618 - 15s - loss: 3.2278e-04 - logcosh: 3.2278e-04 - val_loss: 2.7349e-04 - val_logcosh: 2.7349e-04\n",
      "Epoch 13/40\n",
      "618/618 - 15s - loss: 3.1050e-04 - logcosh: 3.1050e-04 - val_loss: 2.7572e-04 - val_logcosh: 2.7572e-04\n",
      "Epoch 14/40\n",
      "618/618 - 15s - loss: 3.0275e-04 - logcosh: 3.0275e-04 - val_loss: 2.6183e-04 - val_logcosh: 2.6183e-04\n",
      "Epoch 15/40\n",
      "618/618 - 15s - loss: 2.9525e-04 - logcosh: 2.9525e-04 - val_loss: 2.6164e-04 - val_logcosh: 2.6164e-04\n",
      "Epoch 16/40\n",
      "618/618 - 15s - loss: 2.8777e-04 - logcosh: 2.8777e-04 - val_loss: 2.4808e-04 - val_logcosh: 2.4808e-04\n",
      "Epoch 17/40\n",
      "618/618 - 15s - loss: 2.8866e-04 - logcosh: 2.8866e-04 - val_loss: 2.6510e-04 - val_logcosh: 2.6510e-04\n",
      "Epoch 18/40\n",
      "618/618 - 15s - loss: 2.7822e-04 - logcosh: 2.7822e-04 - val_loss: 2.4509e-04 - val_logcosh: 2.4509e-04\n",
      "Epoch 19/40\n",
      "618/618 - 15s - loss: 2.7413e-04 - logcosh: 2.7413e-04 - val_loss: 2.6205e-04 - val_logcosh: 2.6205e-04\n",
      "Epoch 20/40\n",
      "618/618 - 15s - loss: 2.7231e-04 - logcosh: 2.7231e-04 - val_loss: 2.7833e-04 - val_logcosh: 2.7833e-04\n",
      "Epoch 21/40\n",
      "618/618 - 15s - loss: 2.6799e-04 - logcosh: 2.6799e-04 - val_loss: 2.7213e-04 - val_logcosh: 2.7213e-04\n",
      "Epoch 22/40\n",
      "618/618 - 15s - loss: 2.6517e-04 - logcosh: 2.6517e-04 - val_loss: 2.3882e-04 - val_logcosh: 2.3882e-04\n",
      "Epoch 23/40\n",
      "618/618 - 15s - loss: 2.6052e-04 - logcosh: 2.6052e-04 - val_loss: 2.4413e-04 - val_logcosh: 2.4413e-04\n",
      "Epoch 24/40\n",
      "618/618 - 15s - loss: 2.5849e-04 - logcosh: 2.5849e-04 - val_loss: 2.4025e-04 - val_logcosh: 2.4025e-04\n",
      "Epoch 25/40\n",
      "618/618 - 15s - loss: 2.5422e-04 - logcosh: 2.5422e-04 - val_loss: 2.3346e-04 - val_logcosh: 2.3346e-04\n",
      "Epoch 26/40\n",
      "618/618 - 15s - loss: 2.5224e-04 - logcosh: 2.5224e-04 - val_loss: 2.3934e-04 - val_logcosh: 2.3934e-04\n",
      "Epoch 27/40\n",
      "618/618 - 15s - loss: 2.4951e-04 - logcosh: 2.4951e-04 - val_loss: 2.2704e-04 - val_logcosh: 2.2704e-04\n",
      "Epoch 28/40\n",
      "618/618 - 15s - loss: 2.4788e-04 - logcosh: 2.4788e-04 - val_loss: 2.4937e-04 - val_logcosh: 2.4937e-04\n",
      "Epoch 29/40\n",
      "618/618 - 15s - loss: 2.4601e-04 - logcosh: 2.4601e-04 - val_loss: 2.2687e-04 - val_logcosh: 2.2687e-04\n",
      "Epoch 30/40\n",
      "618/618 - 15s - loss: 2.4520e-04 - logcosh: 2.4520e-04 - val_loss: 2.3220e-04 - val_logcosh: 2.3220e-04\n",
      "Epoch 31/40\n",
      "618/618 - 15s - loss: 2.4212e-04 - logcosh: 2.4212e-04 - val_loss: 2.2184e-04 - val_logcosh: 2.2184e-04\n",
      "Epoch 32/40\n",
      "618/618 - 15s - loss: 2.4011e-04 - logcosh: 2.4011e-04 - val_loss: 2.2571e-04 - val_logcosh: 2.2571e-04\n",
      "Epoch 33/40\n",
      "618/618 - 15s - loss: 2.3947e-04 - logcosh: 2.3947e-04 - val_loss: 2.2588e-04 - val_logcosh: 2.2588e-04\n",
      "Epoch 34/40\n",
      "618/618 - 15s - loss: 2.3798e-04 - logcosh: 2.3798e-04 - val_loss: 2.3843e-04 - val_logcosh: 2.3843e-04\n",
      "Epoch 35/40\n",
      "618/618 - 15s - loss: 2.3740e-04 - logcosh: 2.3740e-04 - val_loss: 2.2270e-04 - val_logcosh: 2.2270e-04\n",
      "Epoch 36/40\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Build and compile the model\n",
    "#\n",
    "tcn_ae = TCNAE() # Use the parameters specified in the paper\n",
    "\n",
    "#\n",
    "# Train TCN-AE for 10 epochs. For a better accuracy \n",
    "# on the test case, increase the epochs to epochs=40 \n",
    "# The training takes about 3-4 minutes for 10 epochs, \n",
    "# and 15 minutes for 40 epochs (on Google CoLab, with GPU enabled)\n",
    "#\n",
    "tcn_ae.fit(train_X, train_X, batch_size=32, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Test the model on another Mackey-Glass time series\n",
    "# Might take a few minutes...\n",
    "#\n",
    "start_time = time.time()\n",
    "test_ts_id = 3 # Test the model on Mackey-Glass time series 3\n",
    "test_data = data_gen.build_data(test_ts_id, verbose = 0) # Returns a dictionary\n",
    "\n",
    "#\n",
    "# Take the whole time series... Like the training data, the test data is standardized (zero mean and unit variance)\n",
    "#\n",
    "test_X = test_data[\"scaled_series\"].values[numpy.newaxis,:,:] # We need an extra dimension for the batch-dimension\n",
    "print(\"test_X.shape\", test_X.shape) # This is one long time series\n",
    "anomaly_score = tcn_ae.predict(test_X)\n",
    "print(\"> Time:\", round(time.time() - start_time), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Make a plot of the anomaly-score and see how it matches the real anomaly windows\n",
    "# Vertical red bars show the actual anomalies.\n",
    "# Vertical yellow bars show regions which can be ignored (usually start and \n",
    "# end of a time series, which lead to transient behavior for some algorithms).\n",
    "# The blue curve is the anomaly score.\n",
    "# The red horizontal line indicates a simple threshold, which is the smallest possible value that would not produce a false positive\n",
    "#\n",
    "plot_results(test_data, anomaly_score, pl_range = None, plot_signal = False, plot_anomaly_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Take a look at the MG time series: zoom into the first anomaly\n",
    "#\n",
    "plot_results(test_data, anomaly_score, pl_range = (40000, 42000), plot_signal = True, plot_anomaly_score = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
